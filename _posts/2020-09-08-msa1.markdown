---
layout: post
title:  "MSA 와 오케스트레이션 "
date:   2020-09-08 10:00
author: jizero
tags:	['docker','msa']
---

## MSA 
전체 어플리케이션을 특정 목적을 가진 어플리케이션 단위로 나누는 것


## MSA도입하면서..

### ACID의 문제, API 분산 트랜잭션 
> 1->2->3 api를 순서대로 호출후 리턴을 받아야할때는 어떻게 해야할까?  <br />
- TCC
- saga 패턴
https://www.popit.kr/rest-%EA%B8%B0%EB%B0%98%EC%9D%98-%EA%B0%84%EB%8B%A8%ED%95%9C-%EB%B6%84%EC%82%B0-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98-%EA%B5%AC%ED%98%84-1%ED%8E%B8/

https://kkimsangheon.github.io/2019/06/08/msa3/


> 문자나 이메일같은경우는 어느api에 속해야할까?  <br />
- 메세지 큐의사용
https://velog.io/@tedigom/MSA-%EC%A0%9C%EB%8C%80%EB%A1%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-5Backing-Service-lqk3b7560w


### api Gateway 
API Gateway는 API 서버 앞단에서 모든 API 서버들의 엔드포인트를 단일화 해주는 또다른 서버다.
<br/>
<img src="/assets/img/20200908/111.png" style="max-width:300px;" /> <br/>

[https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/architect-microservice-container-applications/direct-client-to-microservice-communication-versus-the-api-gateway-pattern
](https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/architect-microservice-container-applications/direct-client-to-microservice-communication-versus-the-api-gateway-pattern
)



## MSA 서비스를 6개월동안 해보면서 느낀점..
사내제한서비스에대한 MSA는 필요한가?  => API분리만으로도 MSA장점을 가져갈수있을듯 <br>
팀원이 3명이라면... ?  서비스가 커지기전에 프로토타입서비스를 미리 나눠야할까..?   <br>

### 이미 설계된 아키텍처에 돌을 던져도될까?
현재 하고있는 아키텍처는 다음과 같다. 약간 준-BFF패턴과 같은건데
<img src="/assets/img/20200908/333.png" style="max-width:300px;" /> <br>
MSA대한 공부없이 해당 소스를 도커라이징을 하게되었고 하면서 아래방식에 문제점을 느끼는중이다. <br/>
1. 분리되지않은 API에 Front 분리는 의미없다 <br/>
2. front 공통모듈에대한 부담, 메모리 사용량 , 용량 증가. (공통헤드) <br/>
API가 나눠지지 않은 상태에서의 프론트의 분리가 의미있을까? <br />

#### UI를분리가 필요하다면? 
아래의 패턴 처럼 컴포넌트성이 더 유리할듯 싶다.
BFF 패턴 <br />
[https://medium.com/@giljae/back-end-for-front-end-pattern-bff-4b73f29858d6](https://medium.com/@giljae/back-end-for-front-end-pattern-bff-4b73f29858d6)
컴포넌트성 프론트도 단일도커로 관리하면 좋을듯


#### 도커 CI/CD.. 그리고 의존성 관리
현재의 도커라이징  <br>
- nginx
- application (php)
  - docker volume - front 1  (container 1.. )
  - docker volume - front 2
  - docker volume - front 3

<br /> php composer 의존성관리의경우
aws codebuild 에서 multi-stage build를 사용중이다 <br />

stage-1 <br />
```
FROM composer:1.7 as vendor

COPY database/ database/

COPY composer.json composer.json
COPY composer.lock composer.lock

RUN composer install \
    --ignore-platform-reqs \
    --no-interaction \
    --no-plugins \
    --no-scripts \
    --prefer-dist

```    

stage-2 <br />
```
 
 ... 생략 ..
 COPY --from=vendor /app/vendor/ /var/www/html/vendor/
 ..

```    

로컬환경에서는  multi-stage 테스트는 너무 좋았다.  stage-1도 로컬환경내에서 캐시가 되기 때문에 composer install에대한 부담이 없었다. <br />
aws  codebuild시  composer.json 에대한  composer라이브러리에서 늘 새로 가져온다.. <br />
여러 캐시 서비스를 찾아보는중인데 stage-1 을 캐시화하는 방법을 찾지 못했다.<br />
아니면 젠킨스등을 통해 서버환경에 맞춰서 composer install을 하고 <br />
로컬에서 정적으로 관리 후 소스파일 자체를 올릴지 고민중 이다. <br />











